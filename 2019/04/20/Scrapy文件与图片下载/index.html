<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Scrapy文件与图片下载 | 自强不息</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Media PipelineScrapy为下载item中包含的文件(比如在爬取到产品时，同时也想保存对应的图片)提供了一个可重用的 item pipelines . 这些pipeline有些共同的方法和结构(称之为media pipeline)。">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy文件与图片下载">
<meta property="og:url" content="http://moqiang02.github.io/2019/04/20/Scrapy%E6%96%87%E4%BB%B6%E4%B8%8E%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD/index.html">
<meta property="og:site_name" content="自强不息">
<meta property="og:description" content="Media PipelineScrapy为下载item中包含的文件(比如在爬取到产品时，同时也想保存对应的图片)提供了一个可重用的 item pipelines . 这些pipeline有些共同的方法和结构(称之为media pipeline)。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://moqiang02.github.io/images/Scrapy%E6%96%87%E4%BB%B6%E4%B8%8E%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD/1.png">
<meta property="article:published_time" content="2019-04-20T09:03:32.000Z">
<meta property="article:modified_time" content="2023-08-18T07:22:01.104Z">
<meta property="article:author" content="moqiang">
<meta property="article:tag" content="爬虫">
<meta property="article:tag" content="scrapy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://moqiang02.github.io/images/Scrapy%E6%96%87%E4%BB%B6%E4%B8%8E%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD/1.png">
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">自强不息</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://moqiang02.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Scrapy文件与图片下载" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/04/20/Scrapy%E6%96%87%E4%BB%B6%E4%B8%8E%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD/" class="article-date">
  <time class="dt-published" datetime="2019-04-20T09:03:32.000Z" itemprop="datePublished">2019-04-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Scrapy文件与图片下载
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      

          <!-- rex -->
          
            <!-- 文章目录开始 -->
            
              <div id="toc" class="toc-article">
              <strong class="toc-title" style="cursor:pointer">目录</strong>
              <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Media-Pipeline"><span class="toc-number">1.</span> <span class="toc-text">Media Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E7%94%A8Media-Pipeline"><span class="toc-number">2.</span> <span class="toc-text">启用Media Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A9%E5%B1%95Media-Pipeline"><span class="toc-number">3.</span> <span class="toc-text">扩展Media Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8ImagesPipeline%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87"><span class="toc-number">4.</span> <span class="toc-text">使用ImagesPipeline下载图片</span></a></li></ol>
              </div>
            
            <!-- 文章目录结束 -->	  
          

        <h3 id="Media-Pipeline"><a href="#Media-Pipeline" class="headerlink" title="Media Pipeline"></a>Media Pipeline</h3><p>Scrapy为下载item中包含的文件(比如在爬取到产品时，同时也想保存对应的图片)提供了一个可重用的 item pipelines . 这些pipeline有些共同的方法和结构(称之为media pipeline)。<span id="more"></span><br>我们可以使用FilesPipeline和Images Pipeline来保存文件和图片，他们有以下的一些特点：</p>
<p><strong>Files Pipeline</strong></p>
<ul>
<li>避免重新下载最近已经下载过的数据</li>
<li>指定存储路径</li>
</ul>
<p>FilesPipeline的典型工作流程如下：</p>
<ol>
<li>在一个爬虫里，你抓取一个项目，把其中图片的URL放入 file_urls 组内。</li>
<li>项目从爬虫内返回，进入项目管道。</li>
<li>当项目进入 FilesPipeline，file_urls 组内的URLs将被Scrapy的调度器和下载器（这意味着调度器和下载器的中间件可以复用）安排下载，当优先级更高，会在其他页面被抓取前处理。项目会在这个特定的管道阶段保持“locker”的状态，直到完成文件的下载（或者由于某些原因未完成下载）。</li>
<li>当文件下载完后，另一个字段(files)将被更新到结构中。这个组将包含一个字典列表，其中包括下载文件的信息，比如下载路径、源抓取地址（从 file_urls 组获得）和图片的校验码(checksum)。 files 列表中的文件顺序将和源 file_urls 组保持一致。如果某个图片下载失败，将会记录下错误信息，图片也不会出现在 files 组中。</li>
</ol>
<p><strong>Images Pipeline</strong></p>
<ul>
<li>避免重新下载最近已经下载过的数据</li>
<li>指定存储路径</li>
<li>将所有下载的图片转换成通用的格式（JPG）和模式（RGB）</li>
<li>缩略图生成</li>
<li>检测图像的宽/高，确保它们满足最小限制</li>
</ul>
<p>和FilesPipeline类似，除了默认的字段名不同，image_urls保存图片URL地址，images保存下载后的图片信息。当然，它还提供了一些拓展功能，比如图片的缩略图，过滤图片的尺寸。<br>注意：你需要安装Pillow 库来实现以上的拓展功能。</p>
<h3 id="启用Media-Pipeline"><a href="#启用Media-Pipeline" class="headerlink" title="启用Media Pipeline"></a>启用Media Pipeline</h3><p>要想使用media pipeline，你需要在设置添加一些必要的信息。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同时启用图片和文件管道</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">                  <span class="string">&#x27;scrapy.pipelines.images.ImagesPipeline&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">                  <span class="string">&#x27;scrapy.pipelines.files.FilesPipeline&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">                 &#125;</span><br><span class="line">FILES_STORE = <span class="string">&#x27;D:&#x27;</span>  <span class="comment"># 文件存储路径</span></span><br><span class="line">IMAGES_STORE = <span class="string">&#x27;D&#x27;</span> <span class="comment"># 图片存储路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 避免下载最近90天已经下载过的文件内容</span></span><br><span class="line">FILES_EXPIRES = <span class="number">90</span></span><br><span class="line"><span class="comment"># 避免下载最近90天已经下载过的图像内容</span></span><br><span class="line">IMAGES_EXPIRES = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图片缩略图</span></span><br><span class="line">IMAGES_THUMBS = &#123;</span><br><span class="line">    <span class="string">&#x27;small&#x27;</span>: (<span class="number">50</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;big&#x27;</span>: (<span class="number">250</span>, <span class="number">250</span>),</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 图片过滤器，最小高度和宽度，低于此尺寸不下载</span></span><br><span class="line">IMAGES_MIN_HEIGHT = <span class="number">110</span></span><br><span class="line">IMAGES_MIN_WIDTH = <span class="number">110</span></span><br></pre></td></tr></table></figure>
<p>你可能会好奇文件的命名，在当你启用media pipeline以后，<br>它的默认命名方式是这样的，文件以它们URL的 SHA1 hash 作为文件名。<br>例如，<br>对下面的图片URL:<code>http://www.example.com/image.jpg</code><br>其SHA1 hash 值为:3afec3b4765f8f0a07b78f98c07b83f013567a0a<br>将被下载并存为下面的文件:<code>&lt;IMAGES_STORE&gt;/full/3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg</code></p>
<h3 id="扩展Media-Pipeline"><a href="#扩展Media-Pipeline" class="headerlink" title="扩展Media Pipeline"></a>扩展Media Pipeline</h3><p>下面我们以ImagesPipeline为例来自定义ImagesPipeline，需要重写以下两个方法：</p>
<p><strong>get_media_requests(item, info)</strong><br>在工作流程中可以看到，管道会得到图片的URL并从项目中下载。为了这么做，你需要重写 <code>get_media_requests()</code> 方法，并对各个图片URL返回一个Request:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_media_requests</span>(<span class="params">self, item, info</span>):</span><br><span class="line">    <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">&#x27;image_urls&#x27;</span>]:</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(image_url)</span><br></pre></td></tr></table></figure>
<p>这些请求将被管道处理，当它们完成下载后，结果将以2元素的元组列表形式传送到 <code>item_completed()</code> 方法: 每个元组包含 <code>(success, file_info_or_error)</code>:<br>success 是一个布尔值，当图片成功下载时为 True ，因为某个原因下载失败为False<br>file_info_or_error 是一个包含下列关键字的字典（如果成功为 True）或者出问题时为 Twisted Failure 。<br>url - 文件下载的url。这是从 get_media_requests() 方法返回请求的url。<br>path - 图片存储的路径（类似 IMAGES_STORE）<br>checksum - 图片内容的 MD5 hash<br>item_completed() 接收的元组列表需要保证与 get_media_requests() 方法返回请求的顺序相一致。下面是 results 参数的一个典型值:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="literal">True</span>,</span><br><span class="line">  &#123;<span class="string">&#x27;checksum&#x27;</span>: <span class="string">&#x27;2b00042f7481c7b056c4b410d28f33cf&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;path&#x27;</span>: <span class="string">&#x27;full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;http://www.example.com/files/product1.jpg&#x27;</span>&#125;),</span><br><span class="line"> (<span class="literal">False</span>,</span><br><span class="line">  Failure(...))]</span><br></pre></td></tr></table></figure>
<p>该方法 必须返回每一个图片的URL。</p>
<p><strong>item_completed(results, items, info)</strong><br>当一个单独项目中的所有图片请求完成时,例如，item里面一共有10个URL，那么当这10个URL全部下载完成以后，<code>ImagesPipeline.item_completed()</code> 方法将被调用。默认情况下， <code>item_completed()</code> 方法返回item。</p>
<h3 id="使用ImagesPipeline下载图片"><a href="#使用ImagesPipeline下载图片" class="headerlink" title="使用ImagesPipeline下载图片"></a>使用ImagesPipeline下载图片</h3><p>下面我们用上面学习到的知识来下载一些图片。<br>我们以<code>http://jandan.net/ooxx</code> 为例，把页面上的图片下载下来，并产生缩略图<br>我们新建一个项目，名为jiandan，各个文件内容如下。<br>item.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">JiandanItem</span>(scrapy.Item):</span><br><span class="line">    image_urls = scrapy.Field()<span class="comment">#图片的链接</span></span><br><span class="line">    images = scrapy.Field()</span><br></pre></td></tr></table></figure>

<p>jiandan_spider.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> jiandan.items <span class="keyword">import</span> JiandanItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">jiandanSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;jiandan&#x27;</span></span><br><span class="line">    start_urls = [<span class="string">&quot;http://jandan.net/ooxx&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line"></span><br><span class="line">        item = JiandanItem()</span><br><span class="line">        item[<span class="string">&#x27;image_urls&#x27;</span>] = response.xpath(<span class="string">&#x27;//img//@src&#x27;</span>).extract() <span class="comment">#提取图片链接</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p>settings.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">&#x27;jiandan&#x27;</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">&#x27;jiandan.spiders&#x27;</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">&#x27;jiandan.spiders&#x27;</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;jiandan.pipelines.JiandanPipeline&#x27;</span>:<span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE=<span class="string">&#x27;H:\\jiandan&#x27;</span></span><br><span class="line">IMAGES_THUMBS = &#123;</span><br><span class="line">    <span class="string">&#x27;small&#x27;</span>: (<span class="number">50</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;big&#x27;</span>: (<span class="number">200</span>, <span class="number">200</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>pipelinse.py</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline   <span class="comment">#内置的图片管道</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">JiandanPipeline</span>(<span class="title class_ inherited__">ImagesPipeline</span>):<span class="comment">#继承ImagesPipeline这个类</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_media_requests</span>(<span class="params">self, item, info</span>):</span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">&#x27;image_urls&#x27;</span>]:</span><br><span class="line">            image_url = <span class="string">&quot;http://&quot;</span> + image_url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(image_url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">item_completed</span>(<span class="params">self, results, item, info</span>):</span><br><span class="line">        image_paths = [x[<span class="string">&#x27;path&#x27;</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">&quot;Item contains no images&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>运行这个spider，你会发现，图片已经下载好了，如下图所示。<br><img src="/images/Scrapy%E6%96%87%E4%BB%B6%E4%B8%8E%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD/1.png"></p>
<p>图片内容你可以自己慢慢看。</p>
<hr>
<p>默认情况下，使用ImagePipeline组件下载图片的时候，图片名称是以图片URL的SHA1值进行保存的。<br>重写<code>file_path</code>函数可以修改图片名称以及自定义图片保存路径:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyimgPipeline</span>(<span class="title class_ inherited__">ImagesPipeline</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span></span>):</span><br><span class="line">        image_guid = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> image_guid==<span class="string">&#x27;cover.jpg&#x27;</span>:</span><br><span class="line">            <span class="built_in">dir</span> = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;%s/%s&#x27;</span> % (<span class="built_in">dir</span>,image_guid)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dir1 = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">3</span>]</span><br><span class="line">            dir2 = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;%s/%s/%s&#x27;</span> % (dir1,dir2,image_guid)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_media_requests</span>(<span class="params">self, item, info</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(item, AnimeItem) <span class="keyword">or</span> <span class="built_in">isinstance</span>(item, ImageItem):</span><br><span class="line">            <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">&#x27;image_urls&#x27;</span>]:</span><br><span class="line">                <span class="keyword">yield</span> Request(image_url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">item_completed</span>(<span class="params">self, results, item, info</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(item, AnimeItem) <span class="keyword">or</span> <span class="built_in">isinstance</span>(item, ImageItem):</span><br><span class="line">            image_paths = [x[<span class="string">&#x27;path&#x27;</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">                <span class="keyword">raise</span> DropItem(<span class="string">&quot;Item contains no images&quot;</span>)</span><br><span class="line">            item[<span class="string">&#x27;image_paths&#x27;</span>] = image_paths</span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<blockquote>
<p>转自：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/cnkai/p/7400467.html">Scrapy学习篇（九）之文件与图片下载</a><br>扩展阅读：<a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000009597329">Scrapy框架之利用ImagesPipeline下载图片</a></p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://moqiang02.github.io/2019/04/20/Scrapy%E6%96%87%E4%BB%B6%E4%B8%8E%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD/" data-id="cla0v660500z1g0v19prn3cn4" data-title="Scrapy文件与图片下载" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/" rel="tag">scrapy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/04/20/Tenacity%E2%80%94%E2%80%94Exception-Retry-%E4%BB%8E%E6%AD%A4%E6%97%A0%E6%AF%94%E7%AE%80%E5%8D%95/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          Tenacity——Exception Retry 从此无比简单
        
      </div>
    </a>
  
  
    <a href="/2019/03/22/VUE-%E5%8D%95%E9%A1%B5%E9%9D%A2%E5%BA%94%E7%94%A8-%E4%BF%AE%E6%94%B9%E9%A1%B5%E9%9D%A2title/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">VUE 单页面应用 修改页面title</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/android/">android</a><span class="category-list-count">255</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/apache/">apache</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/flutter/">flutter</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github%E5%8D%9A%E5%AE%A2/">github博客</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/go/">go</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/html-css/">html+css</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/iis/">iis</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">84</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/javascript/">javascript</a><span class="category-list-count">124</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/kotlin/">kotlin</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">68</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mac/">mac</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/memcached/">memcached</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mongodb/">mongodb</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a><span class="category-list-count">74</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/nginx/">nginx</a><span class="category-list-count">42</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/nodejs/">nodejs</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/php/">php</a><span class="category-list-count">186</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">44</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%85%B6%E5%AE%83/">其它</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/">开发工具</a><span class="category-list-count">52</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">开源项目</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94/">生活随笔</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C/">网络</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/">量化交易</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AndroidStudio/" style="font-size: 13.16px;">AndroidStudio</a> <a href="/tags/AndroidUI/" style="font-size: 20px;">AndroidUI</a> <a href="/tags/Android%E4%BA%8B%E4%BB%B6%E6%8B%A6%E6%88%AA/" style="font-size: 11.05px;">Android事件拦截</a> <a href="/tags/Android%E5%BC%80%E6%BA%90/" style="font-size: 16.84px;">Android开源</a> <a href="/tags/CI/" style="font-size: 15.26px;">CI</a> <a href="/tags/CURL/" style="font-size: 12.63px;">CURL</a> <a href="/tags/DEDE/" style="font-size: 17.37px;">DEDE</a> <a href="/tags/Docker/" style="font-size: 14.21px;">Docker</a> <a href="/tags/Flask/" style="font-size: 10.53px;">Flask</a> <a href="/tags/JavaSE/" style="font-size: 18.42px;">JavaSE</a> <a href="/tags/Laravel/" style="font-size: 16.84px;">Laravel</a> <a href="/tags/Maven/" style="font-size: 11.58px;">Maven</a> <a href="/tags/MybatisPlus/" style="font-size: 11.05px;">MybatisPlus</a> <a href="/tags/Puppeteer/" style="font-size: 14.74px;">Puppeteer</a> <a href="/tags/SVN/" style="font-size: 10px;">SVN</a> <a href="/tags/Selenium/" style="font-size: 11.58px;">Selenium</a> <a href="/tags/SpringBoot/" style="font-size: 19.47px;">SpringBoot</a> <a href="/tags/Thinkphp/" style="font-size: 10.53px;">Thinkphp</a> <a href="/tags/UEditor/" style="font-size: 11.58px;">UEditor</a> <a href="/tags/VMware/" style="font-size: 12.11px;">VMware</a> <a href="/tags/Vue/" style="font-size: 18.95px;">Vue</a> <a href="/tags/WebSocket/" style="font-size: 12.63px;">WebSocket</a> <a href="/tags/ecshop/" style="font-size: 14.21px;">ecshop</a> <a href="/tags/scrapy/" style="font-size: 13.68px;">scrapy</a> <a href="/tags/smarty/" style="font-size: 12.11px;">smarty</a> <a href="/tags/socket/" style="font-size: 14.21px;">socket</a> <a href="/tags/sphinx/" style="font-size: 11.58px;">sphinx</a> <a href="/tags/vagrant/" style="font-size: 12.11px;">vagrant</a> <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" style="font-size: 11.05px;">微服务</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/" style="font-size: 15.26px;">数据传输</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 11.58px;">正则</a> <a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15.79px;">消息队列</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 17.89px;">爬虫</a> <a href="/tags/%E9%9B%86%E7%BE%A4/" style="font-size: 16.32px;">集群</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/10/28/%E5%9C%A8git%E4%B8%BB%E5%88%86%E6%94%AF%E6%B8%85%E7%90%86%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A%E7%9A%84%E6%96%B9%E6%A1%88/">在git主分支清理代码注释的方案</a>
          </li>
        
          <li>
            <a href="/2025/10/21/ThinkPHP6-0%E9%83%A8%E7%BD%B2%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">ThinkPHP6.0部署相关问题</a>
          </li>
        
          <li>
            <a href="/2025/08/27/%E5%88%A9%E7%94%A8Jenkins%E4%B8%8EDocker%E5%AE%9E%E7%8E%B0Spring-Boot%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E4%B9%8B%E9%81%93/">利用Jenkins与Docker实现Spring Boot项目的自动化部署之道</a>
          </li>
        
          <li>
            <a href="/2025/08/27/Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B8%AD%E5%90%8E%E7%AB%AF%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5/">Nginx负载均衡中后端节点服务器健康检查</a>
          </li>
        
          <li>
            <a href="/2025/06/19/%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Vue%E4%B8%AD%E7%9A%84Mixin%E6%B7%B7%E5%85%A5/">彻底搞懂Vue中的Mixin混入</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 moqiang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>

<!-- rex -->

<script src="/js/toc.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>